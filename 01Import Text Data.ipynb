{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33d2ca9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T16:43:44.495491Z",
     "start_time": "2023-11-23T16:43:41.547171Z"
    }
   },
   "outputs": [],
   "source": [
    "import raw_utils as util\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "random.seed(1746)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d44b790",
   "metadata": {},
   "source": [
    "## Phishing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdca6e53",
   "metadata": {},
   "source": [
    "### Nazario Phishing Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68fd7e9",
   "metadata": {},
   "source": [
    "We will start with reading the subset of the Phishing Corpus that we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "953aa18f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T16:43:51.824312Z",
     "start_time": "2023-11-23T16:43:51.801326Z"
    }
   },
   "outputs": [],
   "source": [
    "# Paths\n",
    "# cwd = os.getcwd()\n",
    "cwd = r\"D:\\01WorkingDirectory\"\n",
    "nazario_path = os.path.join(cwd, 'data/phishing/nazario/')\n",
    "enron_path = os.path.join(cwd, 'data/enron_mail_20150507/')\n",
    "\n",
    "csv_path = os.path.join(cwd, 'data/csv/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b479cd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T16:43:53.172905Z",
     "start_time": "2023-11-23T16:43:53.152917Z"
    }
   },
   "outputs": [],
   "source": [
    "# Files to be ignored for read_dataset()\n",
    "files_ignored = ['README.txt']\n",
    "files_ignored_recent = ['README.txt', '20051114.mbox',  'phishing0.mbox',  'phishing1.mbox',  'phishing2.mbox',  'phishing3.mbox', 'private-phishing4.mbox']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04edbc27",
   "metadata": {},
   "source": [
    "First, we will read and convert all of the dataset. It is straightforward since it is a collection of .mbox files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d55caed",
   "metadata": {},
   "outputs": [],
   "source": [
    "phishing = util.read_dataset(nazario_path, files_ignored, text_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4586c7c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T13:50:37.014192Z",
     "start_time": "2023-11-20T13:50:36.987420Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10706 entries, 0 to 10705\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   body    10706 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 83.8+ KB\n"
     ]
    }
   ],
   "source": [
    "phishing.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fc41143",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T13:51:43.571444Z",
     "start_time": "2023-11-20T13:51:43.093494Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to D:\\01WorkingDirectory\\data/csv/nazario_full.csv\n"
     ]
    }
   ],
   "source": [
    "util.save_to_csv(phishing, csv_path, 'nazario_full.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e861526a",
   "metadata": {},
   "source": [
    "Then, we will also take the subset of only the recent emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "630849ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T13:52:39.339505Z",
     "start_time": "2023-11-20T13:52:09.024593Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now reading file: phishing-2015\n",
      "Now reading file: phishing-2016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\13636\\.conda\\envs\\p384ped\\lib\\site-packages\\bs4\\builder\\__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now reading file: phishing-2017\n",
      "Now reading file: phishing-2018\n",
      "Now reading file: phishing-2019\n",
      "Now reading file: phishing-2020\n",
      "Now reading file: phishing-2021\n",
      "Now reading file: phishing-2022\n"
     ]
    }
   ],
   "source": [
    "phishing_recent = util.read_dataset(nazario_path, files_ignored_recent, text_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a1c26f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T13:53:13.050998Z",
     "start_time": "2023-11-20T13:53:12.965897Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2163 entries, 0 to 2162\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   body    2163 non-null   object\n",
      "dtypes: object(1)\n",
      "memory usage: 17.0+ KB\n"
     ]
    }
   ],
   "source": [
    "phishing_recent.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82f2ecea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T13:55:17.241361Z",
     "start_time": "2023-11-20T13:55:17.111766Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to D:\\01WorkingDirectory\\data/csv/nazario_recent.csv\n"
     ]
    }
   ],
   "source": [
    "util.save_to_csv(phishing_recent, csv_path, 'nazario_recent.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c74b513",
   "metadata": {},
   "source": [
    "## Legitimate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e694305b",
   "metadata": {},
   "source": [
    "### Enron Email Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb15318",
   "metadata": {},
   "source": [
    "This dataset is very big in size so we will just sample different sized sets of random emails from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0087d4db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T13:58:49.585317Z",
     "start_time": "2023-11-20T13:56:20.478418Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3028 folders will be checked.\n",
      "300452 emails found.\n",
      "Extracting 2000 random emails.\n",
      "Creating output file D:\\01WorkingDirectory\\data/enron_mail_20150507/mbox\\enron_2000.mbox\n",
      "D:\\01WorkingDirectory\\data/enron_mail_20150507/mbox\\enron_2000.mbox was created successfully.\n",
      "Saving to D:\\01WorkingDirectory\\data/csv/enron_text_2000.csv\n"
     ]
    }
   ],
   "source": [
    "filename = util.sample_enron_to_mbox(enron_path, 2000)\n",
    "enron_2000 = util.mbox_to_df(filename, enron_path+'/mbox', text_only=True)\n",
    "util.save_to_csv(enron_2000, csv_path, 'enron_text_2000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e510e85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T14:20:40.772043Z",
     "start_time": "2023-11-20T14:01:09.210599Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3028 folders will be checked.\n",
      "300452 emails found.\n",
      "Extracting 20000 random emails.\n",
      "Creating output file D:\\01WorkingDirectory\\data/enron_mail_20150507/mbox\\enron_20000.mbox\n",
      "1 emails skipped: Headers contain non-ascii characters, or otherwise corrupted email data.\n",
      "D:\\01WorkingDirectory\\data/enron_mail_20150507/mbox\\enron_20000.mbox was created successfully.\n",
      "Saving to D:\\01WorkingDirectory\\data/csv/enron_text_20000.csv\n"
     ]
    }
   ],
   "source": [
    "filename = util.sample_enron_to_mbox(enron_path, 20000)\n",
    "enron_20000 = util.mbox_to_df(filename, enron_path+'/mbox', text_only=True)\n",
    "util.save_to_csv(enron_20000, csv_path, 'enron_text_20000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8f524c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
